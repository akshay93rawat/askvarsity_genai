{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a70656-895d-40e8-9ed5-740a7dfef2bf",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import time\n",
    "import langchain\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9223ed13-6db9-4cfe-a8bc-9fc44a3b13da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load openAI api key\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]= \"your openapi key here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af731461-b5da-4ae2-b9c9-2657083542cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise LLM with required params\n",
    "llm = OpenAI(temperature=0.9, max_tokens=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7150a622-64ff-4bdf-884c-e447a8b28891",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow-heif\n",
    "!pip install opencv-python\n",
    "!pip install pikepdf\n",
    "!pip install pdf2image\n",
    "!pip3 install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c52be4b4cc8bf9",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1634d1e6-f1d0-4a51-864b-16860267b019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "print(\"Loading data...\")\n",
    "pdf_folder_path = \"varsity/\"\n",
    "print(os.listdir(pdf_folder_path))\n",
    "\n",
    "# Load multiple files\n",
    "loaders = [UnstructuredPDFLoader(os.path.join(pdf_folder_path, fn)) for fn in os.listdir(pdf_folder_path)]\n",
    "\n",
    "print(loaders)\n",
    "\n",
    "all_documents = []\n",
    "\n",
    "for loader in loaders:\n",
    "    print(\"Loading raw document...\" + loader.file_path)\n",
    "    raw_documents = loader.load()\n",
    "\n",
    "    print(\"Splitting text...\")\n",
    "    ## Splitting the pdf text\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "    #separators = [\"\\n\\n\",\"\\n\",\" \"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    "    )\n",
    "    documents = text_splitter.split_documents(raw_documents)\n",
    "    all_documents.extend(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0123f8bb676c646",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 2. Create embeddings for these chunks and save them to FAISS index\n",
    "print(\"Creating vectorstore...\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(all_documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90e80b-0e59-4d51-a8af-4075779f9625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Storing vector index create in local\n",
    "file_path=\"vector_index.pkl\"\n",
    "with open(file_path, \"wb\") as f:\n",
    "    pickle.dump(vectorstore, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb7155f-f9e1-4c99-b77e-e42b64e6967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        vectorIndex = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26677b6-7e3e-42b2-81e6-5f078eb1455e",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 4. Create embeddings for these chunks and save them to FAISS index\n",
    "chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=vectorIndex.as_retriever())\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444799cfe945a747",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 5. Generating  Response for prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3102bc9e-c64f-424e-b30e-be71d14d2a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Explain technical analysis with an example in detail?\"\n",
    "\n",
    "langchain.debug=True\n",
    "\n",
    "chain({\"question\": query}, return_only_outputs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
